\documentclass[letterpaper,12pt]{article}

\usepackage{times}
\usepackage{graphicx,color}
\usepackage{amsmath,amssymb,verbatim}
\usepackage{ulem}
\usepackage[colorlinks=false,linkcolor=black,citecolor=black,pdfborder={0 0 0}]{hyperref}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{makecell}
\usepackage{xspace}
\usepackage{url}

\setlength{\hoffset}{0in}
\setlength{\voffset}{0in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{0in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{9in}
\setlength{\marginparsep}{0pt}
\setlength{\marginparwidth}{0pt}
\setlength{\parskip}{9pt}
\setlength{\parindent}{0pt}

\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\openec}{{\sf\small OpenEC}\xspace}
\renewcommand{\ttdefault}{cmtt}

\title{{\bf OpenEC v1.0.0 User Guide}}
\author{ADSLab @ CUHK}
\date{Release: Feb 2019\\}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% abstract
\begin{abstract}
In this user guide, we explain how to install and run \openec atop existing
distributed storage systems (DSSs).  We first explain the preparation steps
for running \openec (\S\ref{sec:installation}).  We next explain how to
integrate \openec with HDFS-3 (\S\ref{sec:hdfs3}), HDFS-RAID
(\S\ref{sec:hdfsraid}), and QFS (\S\ref{sec:qfs}).  We then explain how to
issue basic operations via \openec, including writes, reads (both normal and
degraded reads), and recovery.  Finally, we show how we can add a new erasure
code via \openec.  Please refer to our FAST'19 paper for the design details of
\openec. 
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% introduction

\section{Preparation}
\label{sec:installation}

\openec has been tested in Ubuntu 14.04.  We create a user {\sl openec} and
install the packages under its home directory {\tt /home/openec}.  You may
need the {\tt sudo} access in order to install some of the packages via
{\tt apt-get}. 

Before installing \openec, please first install the following prerequisite
libraries.  

\begin{itemize}

\item cmake v3.1 or higher

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install cmake} 
}%
}
\end{center}

\item g++ v4.8.4

We need a C++ compiler that supports the C++11 standard.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install g++}
}%
}
\end{center}

\item redis v3.2.8 or higher

Download and install {\bf redis-3.2.8.tar.gz}.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf redis-3.2.8.tar.gz} \\
\$ {\tt cd redis-3.2.8} \\
\$ {\tt make} \\
\$ {\tt sudo make install}
}%
}
\end{center}

Install redis as a background daemon. You can just use the default settings.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt cd utils} \\
\$ {\tt sudo ./install\_server.sh}
}%
}
\end{center}

Configure redis to be remotely accessible.
%

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo service redis\_6379 stop}
}%
}
\end{center}

Edit {\sl /etc/redis/6379.conf}. Find the line with {\em bind 127.0.0.0}
and modify it to {\em bind 0.0.0.0}. Then start redis.

%
\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo service redis\_6379 start}
}%
}
\end{center}

\item hiredis

Download and install {\bf hiredis.tar.gz}. 

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf hiredis.tar.gz} \\
\$ {\tt cd hiredis} \\
\$ {\tt make} \\
\$ {\tt sudo make install} 
}%
}
\end{center}

\item gf-complete v1.03

Download and install {\bf gf-complete.tar.gz}.  Note that you may need to
first install {\tt autoconf} and {\tt libtool}. 

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf gf-complete.tar.gz} \\
\$ {\tt cd gf-complete} \\
\$ {\tt ./autogen.sh} \\
\$ {\tt ./configure} \\
\$ {\tt make} \\
\$ {\tt sudo make install}
}%
}
\end{center}

\item ISA-L v2.14.0 or higher

Download and install {\bf isa-l-2.14.0.tar.gz}. Note that you may need to
first install {\tt yasm}, which is required by ISA-L.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf isa-l-2.14.0.tar.gz} \\
\$ {\tt cd isa-l-2.14.0} \\
\$ {\tt ./autogen.sh} \\
\$ {\tt ./configure} \\
\$ {\tt make} \\
\$ {\tt sudo make install}
}%
}
\end{center}
	
\end{itemize}

\section{OpenEC with HDFS-3}
\label{sec:hdfs3}

\subsection{Prerequisites}

The following packages need to be first installed in order to run HDFS-3.

\begin{itemize}

\item maven v3.5.0 or higher

Download {\bf apache-maven-3.5.0-bin.tar.gz}.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf apache-maven-3.5.0-bin.tar.gz}
}%
}
\end{center}

Set the environment variables {\tt M2\_HOME} and {\tt PATH}. You may also need
to set {\tt MVN\_OPTS} if you are behind a proxy.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
{\tt export M2\_HOME=\path{/home/openec/apache-maven-3.5.0}} \\
{\tt export PATH=\$PATH:\$M2\_HOME/bin} 
}%
}
\end{center}



\item java8

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo add-apt-repository ppa:webupd8team/java} \\
\$ {\tt sudo apt-get update} \\
\$ {\tt sudo apt-get install oracle-java8-installer} \\
\$ {\tt sudo apt-get install oracle-java8-set-default}
}%
}
\end{center}

Set the environment variable {\tt JAVA\_HOME}.

\end{itemize}

\subsection{Install HDFS-3 with OpenEC}

Download {\bf hadoop-3.0.0-src.tar.gz} (a copy is available on our project
website) and extract the source code to {\tt /home/openec}. 

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt tar -zxvf hadoop-3.0.0-src.tar.gz} 
}%
}
\end{center}

We configure the environment variables for HDFS-3. It is recommended to
include the following configuration in \path{~/.bashrc}.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt export HADOOP\_SRC\_DIR=/home/openec/hadoop-3.0.0-src} \\
{\tt export HADOOP\_HOME=\${HADOOP\_SRC\_DIR}/hadoop-dist/target/hadoop-3.0.0} \\
{\tt export PATH=\${HADOOP\_HOME}/bin:\${HADOOP\_HOME}/sbin:\${PATH}} \\
{\tt export HADOOP\_CLASSPATH=\${JAVA\_HOME}/lib/tools.jar:\${HADOOP\_CLASSPATH}} \\
{\tt export CLASSPATH=\$JAVA\_HOME/lib:\$CLASSPATH} \\
{\tt export LD\_LIBRARY\_PATH=\$HADOOP\_HOME/lib/native:\${JAVA\_HOME}/jre/lib/\\amd64/server/:/usr/local/lib:\$LD\_LIBRARY\_PATH}
}% 
}
\end{center}

Download {\bf openec-v1.0.0.tar.gz} from our project website and extract the
source code to {\tt /home/openec}.  We can install the patch of \openec into
HDFS-3 by simply running the script {\sl install.sh}.  The script will also
compile the modified source code of HDFS-3.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt tar -zxvf openec-v1.0.0.tar.gz} \\
\$ {\tt cd openec-v1.0.0/hdfs3-integration} \\
\$ {\tt ./install.sh}
}% 
}
\end{center}

Please run the following commands to compile \openec for HDFS-3.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt cd openec-v1.0.0} \\
\$ {\tt cmake . -DFS\_TYPE:STRING=HDFS3} \\
\$ {\tt make}
}% 
}
\end{center}

\subsection{Example Architecture}

Table~\ref{tab:hdfs3arch} shows an example architecture for our HDFS-3
integration.  The \openec controller runs in the same node as the HDFS-3
NameNode.  Each HDFS-3 DataNode is co-located with an \openec agent. Please
distribute the working directories (\path{~/hadoop-3.0.0-src} and
\path{~/openec-v1.0.0}) to all the nodes in the testbed. 

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
IP & HDFS3 & OpenEC \\
\hline
\hline
192.168.0.1 & NameNode & Controller \\
\hline
192.168.0.2 & DataNode & Agent \\
\hline
192.168.0.3 & DataNode & Agent \\
\hline
192.168.0.4 & DataNode & Agent \\
\hline
192.168.0.5 & DataNode & Agent \\
\hline
\end{tabular}
\vspace{-3pt}
\caption{Example architecture for HDFS-3 integration.}
\label{tab:hdfs3arch}
\end{table}

\subsection{HDFS-3 Configuration}

We provide sample configuration files under
\path{openec-v1.0.0/hdfsraid-integration/conf} for HDFS-3.  Here, we show some
of the fields related to the integration of \openec.  You may leave other
fields to be the same as our sample configurations. You can copy our sample
configuration files to \path{HADOOP_HOME/etc/hadoop} and configure your
HDFS-3 there. Please distribute the configuration files to all the nodes in
the testbed.

\begin{itemize}

\item hadoop-env.sh:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
JAVA\_HOME & - & \makecell[l]{Path to java installation. \\e.g. \path{/usr/lib/jvm/java-8-oracle}} \\
\hline
HADOOP\_CLASSPATH & \makecell[l]{\$HADOOP\_HOME/oeclib/*:\\ \$JAVA\_HOME/lib*} & Path to OpenEC and java libraries. \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item core-site.xml:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
fs.defaultFS & hdfs://192.168.0.1:9000 & NameNode configuration. \\
\hline
hadoop.tmp.dir & \makecell[l]{/home/openec/hadoop-3.0.0-src/hadoop-dist/\\target/hadoop-3.0.0} & Base directory for hdfs3 temporary directories.\\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item hdfs-site.xml:

\begin{center}
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
dfs.replication & 1 & Replication factor of HDFS. \\
\hline
dfs.blocksize & 1048576 & The size of a block in bytes. \\
\hline
dfs.block.replicator.classname & \makecell[l]{org.apache.hadoop.hdfs.server.\\blockmanagement.\\BlockPlacementPolicyOEC} & \openec placement integartion. \\
\hline
link.oec & true & \makecell[l]{true: Run HDFS3 with \openec. \\ false: Run HDFS3 without \openec.} \\
\hline
oec.controller.addr & 192.168.0.1 & IP address of \openec controller. \\
\hline
oec.local.addr & - & IP address of a node itself. \\
\hline
oec.pktsize & 131072 & The size of a packet in \openec. \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item workers:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|}
\hline
192.168.0.2\\
\hline
192.168.0.3\\
\hline
192.168.0.4\\
\hline
192.168.0.5\\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\end{itemize}

To start HDFS-3, we run the following commands in the NameNode.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt hdfs namenode -format} \\
\$ {\tt start-dfs.sh}
}% 
}
\end{center}

\section{OpenEC with HDFS-RAID}
\label{sec:hdfsraid}

\subsection{Prerequisites}

The following packages need first to be installed.

\begin{itemize}

\item ant  

Download {\bf apache-ant-1.9.13-bin.tar.gz}.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf apache-ant-1.9.13.-bin.tar.gz}
}%
}
\end{center}

Set the environment variables {\tt ANT\_HOME} and {\tt PATH}.  You may also
need to set {\tt ANT\_OPTS} if you are behind a proxy.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
{\tt export ANT\_HOME=\path{~/apache-ant-1.9.13}} \\
{\tt export PATH=\$PATH:\$ANT\_HOME/bin}
}%
}
\end{center}

\item java8

If you have installed java8, please skip this step.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo add-apt-repository ppa:webupd8team/java} \\
\$ {\tt sudo apt-get update} \\
\$ {\tt sudo apt-get install oracle-java8-installer} \\
\$ {\tt sudo apt-get install oracle-java8-set-default}
}%
}
\end{center}

Set the environment variable {\tt JAVA\_HOME}.

\end{itemize}

\subsection{Install HDFS-RAID with OpenEC}

Download {\bf hadoop-20.tar.gz} (a copy is available on our project website).

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf hadoop-20.tar.gz}
}%
}
\end{center}

We configure the environment variables for HDFS-RAID. It is recommended to
include the following configuration in \path{~/.bashrc}.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
{\tt export HADOOP\_HOME=/home/openec/hadoop-20} \\
{\tt export PATH=\$HADOOP\_HOME/bin:\$HADOOP\_HOME/sbin:\$PATH} \\
{\tt export HADOOP\_CLASSPATH=\${JAVA\_HOME}/lib/tools.jar:\$HADOOP\_CLASSPATH} \\
{\tt export CLASSPATH=\$JAVA\_HOME/lib:\$CLASSPATH} \\
{\tt export LD\_LIBRARY\_PATH=\$HADOOP\_HOME/lib/native:\${JAVA\_HOME}/jre/lib/ \\ amd64/server/:/usr/local/lib:\$LD\_LIBRARY\_PATH}
}%
}
\end{center}

Download {\bf openec-v1.0.0.tar.gz} from our project website and extract the
source code to {\tt /home/openec}.  We can install the patch of \openec into
HDFS-RAID by simply running the script {\sl install.sh}.  The script will also
compile the modified source code of HDFS-RAID.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt tar -zxvf openec-v1.0.0.tar.gz} \\
\$ {\tt cd openec-v1.0.0/hdfs3-integration} \\
\$ {\tt ./install.sh}
}% 
}
\end{center}

We now compile the source code of \openec. Please run the following commands.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt cd openec-v1.0.0} \\
\$ {\tt cmake . -DFS\_TYPE:STRING=HDFSRAID} \\
\$ {\tt make}
}% 
}
\end{center}

\subsection{Example Architecture}

Table~\ref{tab:hdfsraidarch} shows an example architecture for our HDFS-RAID
integration.  The \openec controller runs in the same node as the HDFS-RAID
NameNode.  Each HDFS-RAID DataNode is co-located with an \openec agent. Please
distribute the working directories (\path{~/hadoop-20} and
\path{~/openec-v1.0.0}) to all the nodes in the testbed.

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
IP & HDFS-RAID & OpenEC \\
\hline
\hline
192.168.0.1 & NameNode & Controller \\
\hline
192.168.0.2 & DataNode & Agent \\
\hline
192.168.0.3 & DataNode & Agent \\
\hline
192.168.0.4 & DataNode & Agent \\
\hline
192.168.0.5 & DataNode & Agent \\
\hline
\end{tabular}
\vspace{-3pt}
\caption{Example architecture for HDFS-RAID integration.}
\label{tab:hdfsraidarch}
\end{table}

\subsection{HDFS-RAID Configuration}

We provide sample configuration files 
under \path{openec-v1.0.0/hdfsraid-integration/conf} for HDFS-RAID. 
Here, we show some of the fields in detail. You may leave other fields to be
the same as our sample configurations.  You can copy our sample configuration
files to \path{HADOOP_HOME/conf} and configure your HDFS-RAID there. Please
distribute the configuration files to all the nodes in the testbed. 

\begin{itemize}

\item hadoop-env.sh:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
JAVA\_HOME & - & \makecell[l]{Path to java installation. \\ e.g. \path{/usr/lib/jvm/java-8-oracle}} \\
\hline
HADOOP\_CLASSPATH & \makecell[l]{\$HADOOP\_HOME/oeclib/*:\\ \$JAVA\_HOME/lib*} & \makecell[l]{Path to OpenEC and java libraries.} \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item core-site.xml: 

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
fs.default.name & hdfs://192.168.0.1:9000 & NameNode configuration. \\
\hline
hadoop.tmp.dir & \makecell[l]{/home/openec/hadoop-20/tmp} & Base directory for HDFS-RAID temporary directories.\\
\hline
topology.script.file.name & - & Path to rackAware.sh \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item hdfs-site.xml:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
dfs.http.address & 192.168.0.1:50070 & HTTP address of NameNode \\
\hline
dfs.replication & 1 & Replication factor of HDFS-RAID. \\
\hline
dfs.block.size & 1048576 & The size of a block in bytes. \\
\hline
dfs.block.replicator.classname & \makecell[l]{org.apache.hadoop.hdfs.server.\\namenode.BlockPlacementPolicyOEC} & \openec placement class. \\
\hline
link.oec & true & Run HDFS-RAID with \openec. \\
\hline
oec.controller.addr & 192.168.0.1 & IP address of \openec controller. \\
\hline
oec.local.addr & - & IP address of a node itself. \\
\hline
oec.pktsize & 131072 & The size of a packet in \openec. \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item masters:

\begin{center}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|}
\hline
192.168.0.1 \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item slaves:

\begin{center}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|}
\hline
192.168.0.2 \\
\hline
192.168.0.3 \\
\hline
192.168.0.4 \\
\hline
192.168.0.5 \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\end{itemize}

To start HDFS-RAID, we run the following commands in the NameNode.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt hadoop namenode -format} \\
\$ {\tt start-dfs.sh}
}% 
}
\end{center}

\section{OpenEC with QFS}
\label{sec:qfs}

\subsection{Prerequisites}

The following packages need to be first installed.

\begin{itemize}

\item libboost-regex-dev 1.3.4 or higher

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install libboost-regex-dev}
}%
}
\end{center}

\item libkrb5-dev

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install libkrb5-dev}
}%
}
\end{center}

\item xfslibs-dev

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install xfslibs-dev}
}%
}
\end{center}

\item libssl-dev

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install libssl-dev}
}%
}
\end{center}

\item python-dev

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install python-dev}
}%
}
\end{center}

\item libfuse-dev

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install libfuse-dev}
}%
}
\end{center}

\end{itemize}

\subsection{Install QFS with OpenEC}

Download {\bf qfs-v2.1.1.tar.gz} (a copy is available on our project website).

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf qfs-2.1.1.tar.gz}
}%
}
\end{center}

We configure the environment variables for QFS. It is recommended to include
the following configuration in \path{~/.bashrc}.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt export export QFS\_HOME=/home/openec/qfs} \\
{\tt export PATH=\${QFS\_HOME}/build/release/bin:\${PATH}}
}% 
}
\end{center}

Download {\bf openec-v1.0.0.tar.gz} from our project website and extract the
source code to {\tt /home/openec}.  We can install the patch of \openec into
QFS by simply running the script {\sl install.sh}.  The script will also
compile the modified source code of QFS.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt tar -zxvf openec-v1.0.0.tar.gz} \\
\$ {\tt cd openec-v1.0.0/qfs-integration} \\
\$ {\tt ./install.sh}
}% 
}
\end{center}

We now compile the source code of OpenEC. Please run the following commands.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt cd openec-v1.0.0} \\
\$ {\tt cmake . -DFS\_TYPE:STRING=QFS} \\
\$ {\tt make}
}% 
}
\end{center}

\subsection{Example Architecture}

Table~\ref{tab:qfsarch} shows an example architecture for our QFS integration.
The \openec controller runs in the same node as the QFS metaserver.
Each QFS chunkserver is co-located with an \openec agent. Please distribute
the working directories (\path{~/qfs} and \path{~/openec-v1.0.0}) to all 
the nodes in the testbed.

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
IP & QFS & OpenEC \\
\hline
\hline
192.168.0.1 & Metaserver & Controller \\
\hline
192.168.0.2 & Chunkserver & Agent \\
\hline
192.168.0.3 & Chunkserver & Agent \\
\hline
192.168.0.4 & Chunkserver & Agent \\
\hline
192.168.0.5 & Chunkserver & Agent \\
\hline
\end{tabular}
\vspace{-3pt}
\caption{Example architecture for QFS integration.}
\label{tab:qfsarch}
\end{table}

\subsection{QFS Configuration}

We also provide sample configuration files for QFS. We show some of the fields
in detail and other fields can be the same as in our samples. 

\begin{itemize}

\item MetaServer.conf:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
metaServer.clientPort & 20000 & \makecell[l]{Port number for metaserver to communicate with clients.}\\
\hline
metaServer.chunkServerPort & 30000 & \makecell[l]{Port number for metaserver to communicate with chunkserver.} \\
\hline
metaServer.logDir & - & \makecell[l]{Directory for the log of metaserver.} \\
\hline
metaServer.cpDir & - & \makecell[l]{Directory for the checkpoint of metaserver.} \\
\hline
openec.useoec & true & \makecell[l]{true: enable OpenEC integrations. \\false; disable OpenEC integrations.} \\
\hline
openec.localip & - &  \\
\hline
openec.coorip & 192.168.0.1 & \makecell[l]{IP address of OpenEC controller.} \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item ChunkServer.conf:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
chunkServer.metaServer.hostname & 192.168.0.1 & \makecell[l]{IP address of metaserver.} \\
\hline
chunkServer.metaServer.port & 30000 & \makecell[l]{Port number for metaserver to communicate with chunkserver.} \\
\hline
chunkServer.clientPort & 22000 & \makecell[l]{Port number for chunkserver to communicate with clients.} \\
\hline
chunkServer.chunkDir & - & \makecell[l]{Directory for chunkserver to store chunks.} \\
\hline
chunkServer.pidFile & - & \makecell[l]{File to store pid of chunkserver} \\
\hline
openec.useoec & true & \makecell[l]{true: enable OpenEC integrations. \\false; disable OpenEC integrations.} \\
\hline
openec.localip & - &  \\
\hline
openec.coorip & 192.168.0.1 & \makecell[l]{IP address of OpenEC controller.} \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\end{itemize}

To start the metaserver, please run the following command:

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt metaserver MetaServer.conf}
}% 
}
\end{center}

To start each chunkserver, please run the following command:

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt chunkserver ChunkServer.conf}
}% 
}
\end{center}


\section{OpenEC Configuration}

We provide sample configuration files for \openec under
\path{openec-v1.0.0/conf}.  Table~\ref{tab:sysSetting} explains the default
configuration in our sample.  Table~\ref{tab:ecpolicy} and
Table~\ref{tab:offlinepool} show the configuration of an erasure code and an
offline encoding pool, respectively.

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
controller.address & 192.168.0.1 & IP address of controller. \\
\hline
agents.address & \makecell[l]{/default/192.168.0.2 \\ /default/192.168.0.3 \\ /default/192.168.0.4 \\ /default/192.168.0.5} & \makecell[l]{A list of IP addresses of all agents, in the form of {\sl zone/IP}, \\where {\sl zone} denotes the zone (e.g. rack or datacenter).} \\
\hline
local.address & - & IP address of a node itself. \\ 
\hline
packet.size & 131072 & The size of a packet. \\
\hline
dss.type & - & \makecell[l]{Type of DSS. Please choose from {\sl HDFS3}, {\sl HDFSRAID} and {\sl QFS}}. \\
\hline
dss.parameter & - & \makecell[l]{IP and port of DSS for client access. e.g. {\sl 192.168.0.1, 9000} \\for HDFS3.} \\
\hline
ec.policy & & Table~\ref{tab:ecpolicy}\\
\hline
offline.pool & & Table~\ref{tab:offlinepool}\\
\hline
\end{tabular}
\vspace{-3pt}
\caption{sysSetting.xml for \openec}
\label{tab:sysSetting}
\end{table}

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
ecid & rs\_4\_3 & Unique id for an erasure code. \\
\hline
class & RSCONV & Class name of erasure code implementation. \\
\hline
n & 4 & Parameter N for the erasure code. \\ 
\hline
k & 3 & Parameter K for the erasure code. \\
\hline
w & 1 & Parameter W for the erasure code. \\
\hline
opt & -1 & \makecell[l]{Optimization level for \openec. Four levels of
optimization is provided \\by \openec, including -1, 0, 1, 2. -1: no
optimization are enabled. \\0: BindX is enabled. 1: BindX and BindY
are enabled. 2: Hierarchical \\awareness is enabled.} \\
\hline
\end{tabular}
\vspace{-3pt}
\caption{ec.policy configuration}
\label{tab:ecpolicy}
\end{table}

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
poolid & rs\_4\_3\_pool & Unique id for an offline encoding pool. \\
\hline
ecid & rs\_4\_3 & Erasure code that is applied for the pool. \\
\hline
base & 1 & Block size (in MiB) for the pool, which is no larger than the block size in HDFS3. \\ 
\hline
\end{tabular}
\vspace{-3pt}
\caption{offline.pool configuration}
\label{tab:offlinepool}
\end{table}

To start \openec, we run the following command in controller:

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt cd openec-v1.0.0} \\
\$ {\tt python script/start.py}
}% 
}
\end{center}

\section{Basic Operations}
\label{sec:basic}

We explain how to issue writes, reads (normal and degraded reads), and
recovery via \openec. 

\subsection{Write}

\openec supports two modes to write a file into a DSS: (i) writing a file
with online encoding enabled on the writing path; and (ii) writing a file into
an offline encoding pool, in which a coding group is organized and encoded
offline.

We run OECClient to issue a write request. We show the usage and a
command-line example to write a file (called {\sl input}) of size 3\,MiB and
store it as {\sl /testfile1} with online encoding enabled. The erasure code
for online encoding is {\sl rs\_4\_3} (i.e., RS codes with $n=4$ and $k=3$),
which is configured in {\tt sysSetting.xml}.  Please note that this command
should run in a node that holds an Agent.

Usage:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt ./OECClient write [inputfile] [saveas] [ecid] online [sizeinMB]}
}% 
}
\end{center}

Example:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt ./OECClient write input /testfile1 rs\_4\_3 online 3} 
}% 
}
\end{center}

We now show how to apply offline encoding. We first write the file into our
offline encoding pool.  The command-line example in the following shows that
we write the file ({\sl input}) and store it as {\sl /testfile2}. The offline
encoding pool is {\sl rs\_4\_3\_pool}, which is configured in 
{\tt sysSetting.xml}.  Please note that this command should also run in a node
that holds an Agent.

Usage:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt ./OECClient write [inputfile] [saveas] [poolid] offline [sizeinMB]} 
}% 
}
\end{center}

Example:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt ./OECClient write input /testfile2 rs\_4\_3\_pool offline 3} 
}% 
}
\end{center}

We then run the following command to instruct \openec to start offline
encoding.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt ./OECClient startEncode} 
}% 
}
\end{center}

When the offline encoding for a coding group finishes, we can check the log of
the controller ({\sl coor\_output}).  The following line means that the
offline encoding for a coding group finishes, where {\sl xxxxxx} denotes the
name of the coding group. Note that the name of a coding group is assigned by
\openec.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt offlineEnc for xxxxxx finishes} 
}% 
}
\end{center}


\subsection{Read}

We run OECClient to read a file, either a normal read or a degraded read. 
The difference between a normal read and a degraded read is that for a
degraded read, some physical blocks in the DSS are unavailable (e.g., deleted)
before the read request is issued.  Please note that this command should also
run in a node that holds an Agent.

Usage:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt ./OECClient read [filename] [saveas]} 
}% 
}
\end{center}

Example:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt ./OECClient read /testfile1 output1} \\
\$ {\tt ./OECClient read /testfile2 output2} 
}% 
}
\end{center}

\subsection{Recovery}

For recovery, we can delete some physical blocks in the DSS and then run the
following command to instruct \openec to repair the lost blocks.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt ./OECClient startRepair} 
}% 
}
\end{center}

We can see the following information in the log of controller, which denotes
that \openec finishes repairing a block.  Note that {\sl xxxxxx} is the
corresponding block name in \openec.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt repair for xxxxxx finishes} 
}% 
}
\end{center}

\section{EC Design in OpenEC}
\label{sec:ecdesign}

We introduce how to design a new erasure code in \openec. The following shows
the base class of an erasure code implementation in \openec. To add a new
erasure code, we need to extend this base class and provide the
implementations for {\sl Encode}, {\sl Decode} and {\sl Place} methods. We
provide several erasure code implementations under \path{openec-v1.0.0/src/ec}.
Please refer to our sample implementations there.

\begin{center}
\noindent\fbox{%
\parbox{480pt}{%
{\tt class ECBase \{ } \\
{\tt public: } \\
{\tt    int \_n, \_k, \_w; } \\
{\tt    int \_opt; } \\
{\tt    		} \\
{\tt    ECBase(); } \\
{\tt    ECBase(int n, int k, int w, int opt, vector<string> param); }\\
{\tt 			}\\    
{\tt    virtual ECDAG* Encode() = 0; }\\
{\tt    virtual ECDAG* Decode(vector<int> from, vector<int> to) = 0; }\\
{\tt    virtual void Place(vector<vector<int>>\& group) = 0; } \\
{\tt \}; }
}% 
}

\end{center}

\end{document}

